---
title: 'Lab 11: Modeling Basics'
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document: default
  pdf_document: default
---

Name:  Jeffrey Yang


Collaborated with:  Alyssa, Ashley


This lab is to be done in the lab session (completed outside of class if need be). You can collaborate with your classmates, but you must identify their names above, and you must submit **your own** lab as an knitted PDF/html file. The deadline for each lab session is

- **Deadline for 320.404: W 11:59 PM**
- **Deadline for 320.406: F 11:59 PM**
- **Deadline for 320.407: W 11:59 PM**


**This week's agenda**: Regression and Cross Validation

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning=F)
options(scipen=999)
library(tidyverse)
library(modelr)
library(broom)
```

# Introduction

In this lab, you will build predictive models for board game ratings. The dataset below was scraped from [boardgamegeek.com](www.boardgamegeek.com) and contains information on the top 4,999 board games. Below, you will see a preview of the data

```{r}
bgg<-read.csv("bgg.csv")
bgg2=bgg[,c(4:13,15:20)]
head(bgg2)
```

You will need to modify the code chunks so that the code works within each of chunk (usually this means modifying anything in ALL CAPS). You will also need to modify the code outside the code chunk. When you get the desired result for each step, change `Eval=F` to `Eval=T` and knit the document to HTML/PDF to make sure it works. After you complete the lab, you should submit your HTML/PDF file of what you have completed to Sakai before the deadline.

# Board Game Analysis

### Q1

There are 16 variables and we want to create some more. Create a new dataframe called $bgg3$ where you use the mutate function to create the following variables:

- *duration=2018-year+1*
- *vote.per.year=num_votes/duration*
- *own.per.year=owned/duration*
- *player.range=max_players-min_players*
- *log_vote=log(num_votes+1)*
- *log_own=log(owned+1)*
- *diff_rating=avg_rating-geek_rating*

```{r}
bgg3 = bgg2 %>% 
  mutate(duration=2018-year+1, vote.per.year=num_votes/duration, own.per.year=owned/duration, player.range=max_players-min_players, log_vote=log(num_votes+1), log_own=log(owned+1), diff_rating=avg_rating-geek_rating)
head(bgg3)
```

Question: In complete sentences, what is the purpose of adding 1 for the log transformed variables?
This is so that we don't take the log of 0 and get undefined.

Question: In complete sentences, what is the purpose of adding 1 in the creation of the year variable?
This is so that the year it was created in is included in the duration. 


### Q2

We hypothesize the geek rating increases when the number of votes increases and/or the ownership increases. Create four scatter plots showing the association with geek_rating and the following variables:

- *num_votes*
- *owned*
- *log_vote*
- *log_own*


```{r}
ggplot(bgg3, aes(num_votes, geek_rating)) + geom_point()
ggplot(bgg3, aes(owned, geek_rating)) + geom_point()
ggplot(bgg3, aes(log_vote, geek_rating)) + geom_point()
ggplot(bgg3, aes(log_own, geek_rating)) + geom_point()

```

Question: In complete sentences, describe how the relationship changes when you take the log of the independent variable.

When we take the log, the plot displays more of a linear relationship with geek rating and with a lower slope.

### Q3

Randomly sample approximately 80\% of the data in `bgg3` for a training dataset and the remaining will act as a test set. Call the training dataset `train.bgg` and the testing dataset `test.bgg`.

```{r}
set.seed(320)

bgg4= bgg3 %>%
        mutate(Set=sample(c("Train", "Test"), size=nrow(bgg3), prob = c(.8, .2), replace = T))

train.bgg<-filter(bgg4,Set=="Train")
test.bgg<-filter(bgg4,Set=="Test")
```



### Q4

Now, we want to fit models to the training dataset. Use the `lm()` function to create 3 model objects in R called `lm1`, `lm2`, `lm3` based on the following linear models, respectively:

- $geek_rating=\beta_0+\beta_1 log(num_votes)+\epsilon$
- $geek_rating=\beta_0+\beta_1 log(owned)+\epsilon$
- $geek_rating=\beta_0+\beta_1 log(owned)+ \beta_2 vote.per.year+ \beta_3 weight + \epsilon$

```{r}
lm1 = lm(geek_rating~log_vote,data=train.bgg)
lm2 = lm(geek_rating~log_own,data=train.bgg)
lm3 = lm(geek_rating~log_own + vote.per.year + weight,data=train.bgg)
```

### Q5

Add predictions and residuals for all 3 models to the test set. Create a new data frame called `test.bgg2` and give all your predictions and residuals different names. Use the `str()` function to show these variables were created


```{r}
lm1.pred = predict.lm(lm1, test.bgg)
lm1.res = test.bgg$geek_rating - lm1.pred

lm2.pred = predict.lm(lm2, test.bgg)
lm2.res = test.bgg$geek_rating - lm2.pred

lm3.pred = predict.lm(lm3, test.bgg)
lm3.res = test.bgg$geek_rating - lm3.pred

test.bgg2 = mutate(test.bgg, lm1.pred, lm1.res, lm2.pred, lm2.res, lm3.pred, lm3.res)
head(test.bgg2)
str(test.bgg2)
```


### Q6

Create a function called `MAE.func()` that returns the mean absolute error of the residuals and test your function on the vector called `test`

Solution 1:
```{r}
test=c(-5,-2,0,3,5)

#residuals is vector of residuals
MAE.func = function(residuals){
  return(mean(abs(residuals)))
}

MAE.func(test)
```

### Q7

Use your function to calculate the mean absolute error based on the residuals to calculate the out-of-sample MAE. Make sure you display the mean absolute error from these different models in your output.

```{r}
print("MAE of lm1")
MAE.func(test.bgg2$lm1.res)
print("MAE of lm2")
MAE.func(test.bgg2$lm2.res)
print("MAE of lm3")
MAE.func(test.bgg2$lm3.res)
```

Question: Which model does the best job at predicting the geek rating of these board games?
lm3 is the does the best job at predicting the geek rating.

### Q8

**Challenge** For the third model, use 10-fold cross-validation and measure the mean absolute error. Print this measure of error out.

```{r,eval=F}
cv.bgg = crossv_kfold(bgg3, 10)
train.model.func=function(data){
  mod= lm(geek_rating~log_own + vote.per.year + weight,data=data)
  return(mod)
}
#cv.bgg2 = cv.bgg %>% 
#  mutate(tr.model = map(train, train.model.func))
#cv.bgg2[i,]$test[[1]]
#for (i in range(1:nrow(cv.bgg2))){
#  res = predict.lm(cv.bgg2[i,]$tr.model[[1]], cv.bgg2[i,]$test[[1]]) - 
#}
#DATA4.PREDICT = cv.bgg %>% 
 #         mutate(predict=map2(test,tr.model,~augment(.y,newdata=.x))) %>%
  #        select(predict) %>%
   #       unnest()

```

Question: What is the absolute difference between the out-of-sample mean absolute error measured using a test set and the mean absolute error measured using cross validation? When you type your answer in complete sentences use inline R code to calculate the absolute difference and input it directly into your sentence.

No i give up



