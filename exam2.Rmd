---
title: "R Notebook"
output:
  word_document: default
  html_notebook: default
  pdf_document: default
---

PLEDGE: I will neither give nor receive unauthorized aid in this exam.
Signed: Jeffrey yang


1)

a)
```{r}
babies = read.table('Babies.txt', header = T)
lm_babies = lm(Weight~Age, data = babies)
summary(lm_babies)
```
for y=beta0 + beta1x

beta0 = 6.815
beta1 = 0.0517
se of beta0 = 0.5684
se of beta1 = 0.0052
sigma hat = 2.125


b)
```{r}
#using investr
library(investr)
plotFit(lm_babies, interval = 'confidence', adjust = 'Scheffe', main= 'Work-Hotelling plot', level=0.9)
```
^plot above


c)
```{r}
beta0 = 6.815
beta1 = 0.0517
sigma = 2.125
n=nrow(babies)
fit21 = beta0 + beta1*21
standardt = qt(.975, n-2)
wht = sqrt(2*qf(.95, 2, n-2))
SSX = sum((babies$Age-mean(babies$Age))^2)
se = sigma*sqrt(1/n +(21-mean(babies$Age))^2/SSX)
pse = sigma*sqrt(1+ 1/n +(21-mean(babies$Age))^2/SSX)
c(fit21-standardt*se, fit21+standardt*se)
c(fit21-wht*se, fit21+wht*se)
c(fit21-standardt*pse, fit21+standardt*pse)
fit21
df2 = data.frame(Age=21)
predict.lm(lm_babies, df2, interval = 'confidence', level = 0.95)
print('90% prediction interval')
predict.lm(lm_babies, df2, interval = 'prediction', level = 0.95)
```
at 95% confidence
standard ci for mean weight at 21 days is (6.9301, 8.8712)
work hotelling ci for mean weight at 21 days is (6.6802, 9.1211)
prediction interval for weight at 21 days is (3.5038, 12.2975)



d)
```{r}
bont = qt(1-.1/2, n-2)
wht = sqrt(2*qf(1-.1, 2, n-2))
bont
wht
```
The work hotelling t is larger. The bounds would be narrower with bonferroni. 



2)
a)
```{r}
cars = read.table('USEDCARS1.txt', header = T)
ones = rep(1, nrow(cars))
X = matrix(c(ones, cars$miles, cars$age, cars$odo), nrow = nrow(cars))
Y = cars$costs
XtX = t(X) %*% X
XtX_inverse = solve(XtX)
XtY = t(X) %*% Y
print('X')
head(X)
print('X^tX')
XtX
print('inverse of X^tX')
XtX_inverse
print('X^tY')
XtY
```
^ first matrix is X, 2nd is X^tX, 3rd is X^tX inverse, 4th is X^tY


b)
```{r}
beta = XtX_inverse %*% XtY
e = Y-X%*%beta
SSE = t(e) %*% e
sigma = sqrt(SSE/(nrow(cars)-3-1))
errors = c(sigma*sqrt(XtX_inverse[1,1]),sigma*sqrt(XtX_inverse[2,2]),sigma*sqrt(XtX_inverse[3,3]),sigma*sqrt(XtX_inverse[4,4]))
beta
sigma
errors
```
beta hat = first vector^
sigma hat = 46.65
se of beta0 = 46.83
se of beta1 = 2.6615
se of beta2 = 0.8923
se of beta3 = 0.7245

c) 
```{r}
df = data.frame(miles=10, age=24, odo=28)
a = as.numeric(c(1, df))
pred = as.numeric(t(a)%*%beta)
se = as.numeric(sigma*sqrt(t(a)%*%XtX_inverse%*%a))
pse = as.numeric(sigma*sqrt(1+t(a)%*%XtX_inverse%*%a))
pred + c(-1,0,1)*qt(0.995, nrow(cars)-3-1)*se
pred + c(-1,0,1)*qt(0.95, nrow(cars)-3-1)*pse
```
99% confidence interval for the parameters is (79.6269, 192.5473)
90% prediction interval for cars with the parameters is (45.3162, 226.8580)

The prediction interval is wider.


d)
```{r}
cars_lm = lm(costs~miles+age+odo, data=cars)
summary(cars_lm)
print('99% confidence interval')
predict.lm(cars_lm, df, interval = 'confidence', level = 0.99)
print('90% prediction interval')
predict.lm(cars_lm, df, interval = 'prediction', level = 0.90)
```
Results above ^
The beta values, se of betas, and sigma hat are the same.
The confidence and prediction intervals are the same.


3)
```{r}
gifted = read.table('Gifted.txt', header=T)
all_lm = lm(score~., data=gifted)
four_lm = lm(score~fiq+miq+age1+age10, data=gifted)
summary(all_lm)
summary(four_lm)
```
We prefer the model with all variables since the R-squared and Adjusted R-Squared are larger.


b)
```{r}
hat_values = four_lm$fitted.values
sres = rstandard(four_lm)
sres
boxplot(sres)
```
All of the standardized residuals seem to be within a reasonable range, -3 to 3. Which would indicate that there aren't any outliers in the hat values or standardized residuals.

c)
```{r}
plot(gifted$fiq, sres,pch=20,xlab='fiq',ylab='standardized residual', main='Rstandard versus fiq')
plot(gifted$miq, sres,pch=20,xlab='miq',ylab='standardized residual', main='Rstandard versus miq')
plot(gifted$age1, sres,pch=20,xlab='age1',ylab='standardized residual', main='Rstandard versus age1')
plot(gifted$age10, sres,pch=20,xlab='age10',ylab='standardized residual', main='Rstandard versus age10')
plot(gifted$read, sres,pch=20,xlab='read',ylab='standardized residual', main='Rstandard versus read')
plot(gifted$tved, sres,pch=20,xlab='tved',ylab='standardized residual', main='Rstandard versus tved')
plot(gifted$tvcart, sres,pch=20,xlab='tvcart',ylab='standardized residual', main='Rstandard versus tvcart')
plot(hat_values, sres,pch=20,xlab='fitted',ylab='standardized residual', main='Rstandard versus fitted')
qqnorm(sres)
qqline(sres)
```
The standard residual plots do not seem to indicate any problems. The standard residuals appear to be randomly distributed. The standardized residuals might not be normally distributed since the qqplot is not very linear.


d)
```{r}
ones = rep(1, nrow(gifted))

df = data.frame(fiq=gifted$fiq, miq=gifted$miq, age1 = gifted$age1, age10=gifted$age10)
ci=predict.lm(four_lm, df, interval = 'confidence', level = 0.95)
plot(seq(from = 1, to = 36, by = 1), hat_values, ylab = 'fitted', xlab='child # by row', col='blue', ylim = c(145, 175), main='Model1 over Model0')
points(seq(from = 1, to = 36, by = 1), ci[,'lwr'], col='blue', pch=4)
points(seq(from = 1, to = 36, by = 1), ci[,'upr'], col='blue', pch=4)
points(seq(from = 1, to = 36, by = 1), all_lm$fitted.values, col='red')

df = data.frame(fiq=gifted$fiq, miq=gifted$miq, age1 = gifted$age1, age10=gifted$age10, read = gifted$read, tved = gifted$tved, tvcart = gifted$tvcart)
ci=predict.lm(all_lm, df, interval = 'confidence', level = 0.95)
plot(seq(from = 1, to = 36, by = 1), all_lm
     $fitted.values, ylab = 'fitted', xlab='child # by row', col='red', ylim = c(145, 175), main='Model1')
points(seq(from = 1, to = 36, by = 1), ci[,'lwr'], col='red', pch=4)
points(seq(from = 1, to = 36, by = 1), ci[,'upr'], col='red', pch=4)
```
I would not say there are significant differences between the two models. All of the values fitted by model 1 can be found with the confidence intervals of model 0. The intervals of model 1 are only slightly larger than model 0 and in similar regions. 